{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "46a2f474-f41a-4b50-8ab5-bd8a2791380e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\brian\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import nltk\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b08939fe-3583-4943-897d-45e423a7fed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads pretrained model for vectorizing sentences, Word2Vec\n",
    "path = \"GoogleNews-vectors-negative300.bin.gz\"\n",
    "model = KeyedVectors.load_word2vec_format(path, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4b24e45-de75-4f66-b349-faaa5cb5d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nltk.RegexpTokenizer(r'\\w+')\n",
    "def embedSentence(row):\n",
    "    #uses nltk to seperate sentence into words omitting punctuation\n",
    "    tokens = tokenizer.tokenize(row)\n",
    "    #averages all token vectors\n",
    "    vector = np.array([0]*300)\n",
    "    count = 0\n",
    "###################Need to fix bug with possible zero count\n",
    "    for i in tokens:\n",
    "        if i in model: #only adds tokens present in the model\n",
    "            vector = vector + model.get_vector(i)\n",
    "            count += 1\n",
    "    vector = vector/max(1, count)\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb2f7ff8-e2de-41e1-a8d1-c46545f94a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loads emotion training csv\n",
    "df = pd.read_csv(\"emotions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cb05deba-0640-4f35-b6a6-994212c3f932",
   "metadata": {},
   "outputs": [],
   "source": [
    "#establishes x, y as input, ouput\n",
    "#embeds all x from word to values\n",
    "X = df[\"text\"].apply(embedSentence)\n",
    "y = df[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "70e00abc-2194-41ce-9f52-785acd650544",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split x, y into training\n",
    "X = x\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=0)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=0.4, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dd8d53e8-9aa6-4fd8-a41c-a05c8c02d14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#builds tensorflow model\n",
    "tf_model = tf.keras.Sequential([\n",
    "                                tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "                                tf.keras.layers.Dense(300, activation=\"relu\"),\n",
    "                                tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67a548fa-8206-4e99-a7ca-98d2610d837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "                loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "079d6c38-c318-4919-aa7c-f5bb5b633ff7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tf_model\u001b[38;5;241m.\u001b[39mevaluate(X_train, y_train)\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_cpu\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\.conda\\envs\\tf_cpu\\Lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[1;34m(value, ctx, dtype)\u001b[0m\n\u001b[0;32m    106\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[0;32m    107\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m--> 108\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ops\u001b[38;5;241m.\u001b[39mEagerTensor(value, ctx\u001b[38;5;241m.\u001b[39mdevice_name, dtype)\n",
      "\u001b[1;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type numpy.ndarray)."
     ]
    }
   ],
   "source": [
    "tf_model.evaluate(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05123368-a9fc-4039-b0fc-246692904c83",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_cpu",
   "language": "python",
   "name": "tf_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
